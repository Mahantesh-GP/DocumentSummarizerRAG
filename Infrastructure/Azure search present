 Document Preparation
All documents are stored in Azure Blob Storage.

Azure Cognitive Search Indexer is used to automatically read and process these files using built-in OCR and custom skills if needed.

Document types are identified and tagged based on metadata or filename conventions to support targeted downstream processing.

2. Prompt-Based LLM Analysis
Azure Knowledge Agent is integrated to enable natural language querying over indexed documents.

Custom prompt templates are crafted to extract structured insights from unstructured content.

Special emphasis on handling name variations (e.g., reversed names, partial names, phonetic matches) using prompt engineering.

LLM queries run in real-time or on demand against the Cognitive Search index.

3. Key Extraction Aspects
Extracted fields include names, addresses, dates, document types, and legal attributes.

Prompts and search strategies are tailored to support fuzzy matching, semantic understanding, and contextual reasoning.

Results returned are used for UI display and manual review, enabling users to validate and take action on matched records.

Let me know if you want this written as a script for your presentation, or if you need a fourth section for UI/Review/Action.








You said:
Classification we are not using anything. Simply CSV files Stored in blob run indexer for text extract 


ChatGPT said:
Perfect — thanks for the clarification. Here's the final updated content based on your actual architecture (no classification, just CSV/PDFs in blob, indexed via Azure Indexer, and queried via Knowledge Agent):

1. Document Preparation
All files (e.g., CSV, PDF) are directly uploaded to Azure Blob Storage.

An Azure Cognitive Search Indexer runs on the blob container to extract raw content using built-in text extraction and OCR where needed.

No pre-processing or classification is applied — all documents are processed uniformly.

2. Prompt-Based LLM Analysis
Azure OpenAI Knowledge Agent is used to query the indexed content using natural language prompts.

Prompts are crafted specifically to handle name variations (e.g., “John Smith”, “Smith John”, initials, or partial matches).

This prompt-based LLM interaction ensures semantic understanding of search queries rather than relying only on exact text match.

3. Key Extraction Aspects
The agent extracts information like names, addresses, and related metadata based on prompt context.

It supports fuzzy and contextual search, helping retrieve relevant records even when names are in different order or form.

This output is used in the UI layer for displaying search results and allowing users to review document content.
