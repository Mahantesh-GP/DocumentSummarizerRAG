Pick #1 — Elastic Cloud on Azure (Managed Elasticsearch).
Closest to what you already built in Azure Cognitive Search (Lucene analyzers, fuzziness, synonyms), plus the official Phonetic Analysis plugin (Soundex/Metaphone/Double-Metaphone). It’s a managed service that runs in Azure regions (US East/Virginia) with HA, snapshots, and upgrades handled for you. This gives you scale to billions of docs with familiar query DSL and the least code change. 

Pick #2 — SearchStax Managed Solr on Azure.
If your dataset has lots of multilingual names and you want the strongest built-in phonetics, Solr’s Beider-Morse Phonetic Matching (BMPM) is excellent and native (no extra plugin). SearchStax runs SolrCloud for you on Azure with HA. 

Pick #3 — Azure Cache for Redis (Enterprise) + RediSearch.
Best when the indexed fields are tiny (e.g., names + a few attributes) and you want ultra-low latency. RediSearch supports fuzzy + phonetic (e.g., PHONETIC "dm:en") right in Azure-managed Redis. But for 1.36B docs, RAM sizing can get pricey; use only if your index can be very compact or sharded. 


---

Why I recommend Elastic Cloud (for you)

Minimum rework: Very similar analyzers/queries to Azure Search; easy to replicate your custom analyzer stack (ASCII-folding, token filters, synonyms) and just add the phonetic filter. 

Proven scale & HA: Horizontal sharding/replication, managed snapshots, and Azure-region deployment. 

Cost control: You size nodes/storage directly (hot/warm tiers, compression), often cheaper than per-GB managed index pricing at your scale.



---

Quick next steps (Elastic Cloud on Azure, East US 2)

1. Region: Choose the Azure US-East/Virginia option closest to East US 2. 


2. Analyzer: Create an index with:

asciifolding + lowercase

tokenizer suitable for names (standard/whitespace)

phonetic token filter (e.g., double_metaphone), and a normal field for fuzzy (edit-distance) queries. 



3. Ingest: Bulk load; store compact fields only (avoid storing large blobs in the index—keep them in Blob Storage, store IDs/metadata in ES).


4. Query pattern:

Use multi_match with fuzziness: "AUTO" on the normal field;

OR search the phonetic field for “sounds-like” matches;

Combine with filters (order no., date, etc.) for precision.



5. Sizing: Start with a small hot tier (e.g., 3 data nodes, 1–2TB each) + replicas; adjust shard count to keep each primary shard ≤50–75GB once loaded (easier rebalancing). Monitor heap, segment merging, and I/O before scaling.




---

When to prefer Solr (SearchStax)

You specifically want Beider-Morse (often better for diverse surnames than Double-Metaphone). Managed Solr on Azure gives you BMPM out-of-the-box and SolrCloud HA. 


When to prefer Redis + RediSearch

Your “search” is essentially name lookups on a compact schema and you need blazing latency. Define TEXT PHONETIC "dm:en" on the name field; queries use fuzzy operators. Just be mindful of RAM at 1.36B docs. 
